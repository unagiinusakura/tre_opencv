{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セクション4:画像処理・画像解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. アファイン変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/grapes.jpg')\n",
    "h, w = img.shape[:2]\n",
    "dx , dy = 30, 30  #画像のピクセル数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の平行移動\n",
    "afn_mat = np.float32([[1,0,dx], [0,1,dy]]) #変換行列の定義\n",
    "img_afn = cv2.warpAffine(img, afn_mat, (w,h))#アファイン変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('trans', img_afn)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の回転\n",
    "rot_mat = cv2.getRotationMatrix2D((w/2, h/2), 40, 1)  # 画像の中心、開園角度、画像を拡大・縮小するかどうか\n",
    "img_afn2 = cv2.warpAffine(img, rot_mat, (w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('rotation', img_afn2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25.透視変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/drive.jpg')\n",
    "h, w = img.shape[:2]\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "per1 = np.float32([[100, 500], [300, 500], [300, 100], [100, 100]]) #変換前の四隅の点位置\n",
    "per2 = np.float32([[100, 500], [300, 500], [280, 200], [150, 200]]) #変更後の四隅の点位置\n",
    "\n",
    "psp_matrix = cv2.getPerspectiveTransform(per1, per2)\n",
    "img_psp = cv2.warpPerspective(img, psp_matrix, (w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('psp', img_psp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27.畳み込みの基礎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3)) / 9.0 # 1/9フィルタを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Lena.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_kel = cv2.filter2D(img, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_kel)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobelフィルタ\n",
    "kernel2 = np.zeros((3,3))\n",
    "kernel2[0,0] = 1\n",
    "kernel2[1,0] = 2\n",
    "kernel2[2,0] = 1\n",
    "kernel2[0,2] = -1\n",
    "kernel2[1,2] = -2\n",
    "kernel2[2,2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -1.],\n",
       "       [ 2.,  0., -2.],\n",
       "       [ 1.,  0., -1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ke2 = cv2.filter2D(img, -1, kernel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_ke2)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28.　画像の平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/buildings.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur = cv2.blur(img, (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_blur)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ガウシャンフィルター\n",
    "img_ga = cv2.GaussianBlur(img, (9,9), 2) #第3引数はσ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_ga)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メジアンフィルター\n",
    "img_me = cv2.medianBlur(img, 5) #枠の中の中央値を使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_me)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非線形フィルタのBilateralフィルタを使う\n",
    "img_bi = cv2.bilateralFilter(img, 20, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_bi)\n",
    "cv2.imshow('src', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30.エッジの検出(Sobel/Laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Lena.jpg', 0)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobelフィルタ\n",
    "img_sobelx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3) #2引数はビット深度、x方向に微分の場合は3と4の引数は1,0\n",
    "img_sobely = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3) #2引数はビット深度、y方向に微分の場合は3と4の引数は0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 絶対数に変換\n",
    "img_sovelx = cv2.convertScaleAbs(img_sobelx)\n",
    "img_sovely = cv2.convertScaleAbs(img_sobely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('x', img_sobelx)\n",
    "cv2.imshow('y', img_sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacianフィルタ\n",
    "img_lap = cv2.Laplacian(img, cv2.CV_32F) #2引数はビット深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lap = cv2.convertScaleAbs(img_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('lap', img_lap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 強調させるには画像の値を2倍にする\n",
    "img_lap = img_lap *2\n",
    "cv2.imshow('lap', img_lap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian & GaussianBlur\n",
    "img_blur = cv2.GaussianBlur(img, (3, 3), 2)\n",
    "img_lap2 = cv2.Laplacian(img_blur, cv2.CV_32F)\n",
    "img_lap2 = cv2.convertScaleAbs(img_lap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('lap', img_lap2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 強調させるには画像の値を2倍にする\n",
    "img_lap2 = img_lap2 *2\n",
    "cv2.imshow('lap', img_lap2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.エッジの検出(Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Lena.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_canny = cv2.Canny(img, 10, 100) #低いエッジと高いエッジの２つの閾値を設定する\n",
    "cv2.imshow('Canny', img_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_canny = cv2.Canny(img, 100, 200) #低いエッジと高いエッジの２つの閾値を設定する\n",
    "cv2.imshow('Canny', img_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.直線・円の検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/road.jpg')\n",
    "img_g = cv2.imread('data/src/road.jpg',0)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_canny = cv2.Canny(img_g, 300, 450)\n",
    "cv2.imshow('img_canny', img_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLines(img_canny, 1, np.pi/180, 100) #第2引数はロウの刻み幅,シータの刻み幅、組み合わせ回数の値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lines[:]:\n",
    "    rho = i[0][0]\n",
    "    theta = i[0][1]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = rho * a\n",
    "    y0 = rho * b\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('data/src/grapes.jpg')\n",
    "img2_g = cv2.imread('data/src/grapes.jpg', 0)\n",
    "cv2.imshow('img', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "circles = cv2.HoughCircles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles(img2_g, cv2.HOUGH_GRADIENT, dp = 1, minDist=1, param1=20, param2=35, minRadius=1, maxRadius=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in circles[0]:\n",
    "    cv2.circle(img2, (i[0],i[1]),i[2], (255, 0, 0), 1)\n",
    "    \n",
    "cv2.imshow('img', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.モルフォロジー演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/floor.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モルフォロジー演算するには画像が2値化されている必要がある\n",
    "ret, img_th = cv2.threshold(img, 110, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('img', img_th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), dtype=np.uint8)\n",
    "img_d = cv2.dilate(img_th, kernel)\n",
    "img_e = cv2.erode(img_th, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_th)\n",
    "cv2.imshow('e', img_e)\n",
    "cv2.imshow('d', img_d)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロージング\n",
    "img_c = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('c', img_c)\n",
    "cv2.imshow('d', img_d)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 34. インペイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Bus.jpg')\n",
    "img_mask = cv2.imread('data/src/Mask.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Mask', img_mask)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスク画像を2値化\n",
    "thresh = 1\n",
    "ret, img_bin = cv2.threshold(img_mask, thresh, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('img', img_bin)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dst = cv2.inpaint(img, img_bin, 3, cv2.INPAINT_NS)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('inpaint', img_dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 36. 特徴抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/buildings.jpg')\n",
    "img_g = cv2.imread('data/src/buildings.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harrisのコーナー検出\n",
    "img_harris = copy.deepcopy(img)\n",
    "img_dst = cv2.cornerHarris(img_g, 2, 3, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_harris[img_dst > 0.05 * img_dst.max()] = [0, 0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_harris)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAZEで特徴点を表示\n",
    "img_kaze = copy.deepcopy(img)\n",
    "kaze = cv2.KAZE_create()\n",
    "kp1 = kaze.detect(img, None) #特徴抽出して特徴点を求める\n",
    "img_kaze = cv2.drawKeypoints(img_kaze, kp1, None)\n",
    "cv2.imshow('img', img_kaze)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKAZEで特徴点を表示\n",
    "img_kaze = copy.deepcopy(img)\n",
    "kaze = cv2.AKAZE_create()\n",
    "kp1 = kaze.detect(img, None) #特徴抽出して特徴点を求める\n",
    "img_kaze = cv2.drawKeypoints(img_kaze, kp1, None)\n",
    "cv2.imshow('img', img_kaze)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBEで特徴点を表示\n",
    "img_orb = copy.deepcopy(img)\n",
    "orb = cv2.ORB_create()\n",
    "kp2 = orb.detect(img_orb)\n",
    "img_orb = cv2.drawKeypoints(img_orb, kp2, None)\n",
    "cv2.imshow('img', img_orb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 37.顔検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencvデフォルトの顔検出器\n",
    "HAAR_FILE = \"C:/Users/mikam/Anaconda3/pkgs/opencv3-3.1.0-py35_0/Library/etc/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "cascade = cv2.CascadeClassifier(HAAR_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Solvay_conference_1927.jpg')\n",
    "img_g = cv2.imread('data/src/Solvay_conference_1927.jpg', 0)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cascade.detectMultiScale(img_g) #顔の場所座標を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, w, h in face:\n",
    "    cv2.rectangle(img, (x,y),(x+w, y+h), (0,0,255),1)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 38.ブロブの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Blob.png')\n",
    "img_g = cv2.imread('data/src/Blob.png', 0)\n",
    "cv2.imshow('img', img_g)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブロブの検出には2値化画像が必要\n",
    "ret, img_bi = cv2.threshold(img_g,100, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('img', img_bi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLabels, labelImage, stats, centroids = cv2.connectedComponentsWithStats(img_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blob = copy.deepcopy(img)\n",
    "h, w = img_g.shape\n",
    "color = [[255,0,0], [0,255,0], [0,0,255], [255,255,0]]\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        if labelImage[y,x] >0:\n",
    "            img_blob[y,x] = color[labelImage[y,x]-1]\n",
    "\n",
    "for i in range(1, nLabels):\n",
    "    xc = int(centroids[i][0])\n",
    "    yc = int(centroids[i][1])\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    scale = 1\n",
    "    color = (255,255,255)\n",
    "    cv2.putText(img_blob, str(stats[i][-1]), (xc, yc), font, scale, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_blob)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 39.輪郭の検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/src/Blob.png')\n",
    "img_g = cv2.imread('data/src/Blob.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img_bi = cv2.threshold(img_g,100, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_con, contours, hierarchy = cv2.findContours(img_bi,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img_contour = cv2.drawContours(img, contours, -1, (255,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img_contour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
